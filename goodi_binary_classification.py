# -*- coding: utf-8 -*-
"""Goodi_binary_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H_kXZe56yBWYpQxkFc2ecMkFsGhvoPuM
"""

from google.colab import drive

drive.mount('/content/gdrive')

import pandas as pd
features_data = pd.read_csv("/content/gdrive/MyDrive/Goodi_ML_project/results.csv")
properties = list(features_data.columns.values)

y = features_data.take([16], axis=1).copy()
X = features_data.drop(features_data.columns[-1],axis=1)
print(X[0:30])
X = X / 10
print(X.shape)
print(y.shape)
print(X[0:30])
print(y[0:30])

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
print(X_train)
print(y_train)

import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
import numpy as np
import os

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(16,)),
    keras.layers.Dense(64, activation=tf.nn.relu),
	keras.layers.Dense(64, activation=tf.nn.relu),
    keras.layers.Dense(1, activation=tf.nn.sigmoid),
])

optim = keras.optimizers.Adam(lr=0.001)
model.compile(optimizer=optim,
              loss='binary_crossentropy',
              metrics=['accuracy'])



checkpoint_path = "/content/gdrive/MyDrive/Goodi_ML_project/cp4.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

model.load_weights(checkpoint_path)

# Create a callback that saves the model's weights
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)
#X_train = X_train / 10.0
model.fit(X_train, y_train, epochs=100, batch_size=1,callbacks=[cp_callback])


test_loss, test_acc = model.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

#test_loss, test_acc = model.evaluate(X_test, y_test)
test_loss, test_acc = model.evaluate(X_train, y_train)
print('Test accuracy:', test_acc)

import os
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"

import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
import numpy as np
import os

# model = keras.Sequential([
#     keras.layers.Flatten(input_shape=(16,)),
#     keras.layers.Dense(64, activation=tf.nn.relu),
# 	keras.layers.Dense(64, activation=tf.nn.relu),
#     keras.layers.Dense(1, activation=tf.nn.sigmoid),
# ])
print(model.summary())

# optim = keras.optimizers.Adam(lr=0.001)
# model.compile(optimizer=optim,
#               loss='binary_crossentropy',
#               metrics=['accuracy'])



checkpoint_path = "/content/gdrive/MyDrive/Goodi_ML_project/cp4.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)



# loss and optimizer
# loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)
# optim = keras.optimizers.Adam(lr=0.001)
# metrics = ["accuracy"]

# model.compile(loss=loss, optimizer=optim, metrics=metrics)

checkpoint_path = "/content/gdrive/MyDrive/Goodi_ML_project/cp4.ckpt"

#model.load_weights(checkpoint_path)

arr = os.listdir('/content/gdrive/MyDrive/Goodi_ML_project/testing_files')
for i in range(0, len(arr)):
  # load the csv data
  features_data = pd.read_csv('/content/gdrive/MyDrive/Goodi_ML_project/testing_files/' + arr[i])

  y = features_data.take([16], axis=1).copy()
  X = features_data.drop(features_data.columns[-1],axis=1)
  X = X / 10
  
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20000, random_state=0)
  #print(X_test.shape)
  #print(y_test.shape)

  # evaulate
  #print(arr[i])
  test_loss, test_acc = model.evaluate(X_test, y_test)
  print('Test accuracy:', test_acc, " File name:" , arr[i] )

import os
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"

import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
import numpy as np
import os


arr = os.listdir('/content/gdrive/MyDrive/Goodi_ML_project/testing_files')
for i in range(0, len(arr)):
  # load the csv data
  features_data = pd.read_csv('/content/gdrive/MyDrive/Goodi_ML_project/testing_files/' + arr[i])
  (x_train, y_train) , (x_test , y_test) = split_data(features_data, 0.1)
  # print(x_train.shape)
  # print(y_train.shape)
  # print(x_test.shape)
  # print(y_test.shape)
  # evaulate
  print(arr[i])
  model.evaluate(x_test, y_test.squeeze().argmax(axis=1), batch_size=1, verbose=2)